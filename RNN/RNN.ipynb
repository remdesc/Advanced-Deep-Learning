{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copie de Copie de RNN_Lab.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Recurrent Neural Networks**\n",
        "The aim of this lab is to built a classification algorithms using LSTM and CNN on dynamic data. The lab is inspired on 'Advanced Data science, by Srivatsan Srinivasan, Pavlos Protopapas, Chris Tanner course' \n",
        "\n",
        "**Exercise 1**\n",
        "we aim to perform sentiment classification on a movie review dataset. We would to build a convolutional neural net, a recurrent net and combine one or more of them to understand and compare performance of each of them. A sentence can be thought of as a sequence of words that collectively represent meaning. Individual words impact the meaning. Thus, the context matters; words that occur earlier in the sentence influence the sentence's structure and meaning in the latter part of the sentence (e.g., Jean asked Clara if she were going to the library today). Likewise, words that occur later in a sentence can affect the meaning of earlier words (e.g., Apple is an interesting company). "
      ],
      "metadata": {
        "id": "Kj5Qsu0vz7yI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy\n",
        "from keras.datasets import imdb\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM, SimpleRNN\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.layers import Flatten\n",
        "from keras.preprocessing import sequence\n",
        "from keras.layers.convolutional import Conv1D\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.convolutional import MaxPooling1D\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "from keras.layers import Input\n",
        "from keras.layers.embeddings import Embedding\n",
        "import numpy as np\n",
        "# fix random seed for reproducibility\n",
        "numpy.random.seed(1)"
      ],
      "metadata": {
        "id": "V3pbBhue1b2-"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We want to have a finite vocabulary to make sure that our word matrices are not arbitrarily small\n",
        "vocabulary_size = 10000\n",
        "\n",
        "# We also want to have a finite length of reviews and not have to process really long sentences.\n",
        "max_review_length = 500"
      ],
      "metadata": {
        "id": "dgyeN9jH14PC"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The embedding (seen in Transformer course) is a function representing each word by a unique number (integer) as it takes less memory than strings. There are an infinite number of ways to create such embeddings, and since these representations have such a great influence on the performance of our models, there has been an incredible amount of research dedicated to this very aspect. In general, though, one can view the embedding process as a linear projection from one vector space to another (e.g., a vector space of unique words being mapped to a world of fixed-length, dense vectors filled with continuous-valued numbers)."
      ],
      "metadata": {
        "id": "NzEsn-GJ30wu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Load data**"
      ],
      "metadata": {
        "id": "oKqyKs_42B8K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=vocabulary_size)\n",
        "print('Number of reviews', len(X_train))\n",
        "print('Length of first and fifth review before padding', len(X_train[0]) ,len(X_train[4]))\n",
        "print('First review', X_train[0])\n",
        "print('First label', y_train[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "roXlSWNY2E_n",
        "outputId": "6b6de7ce-90ed-4f5c-f415-b5d30f77e4ef"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of reviews 25000\n",
            "Length of first and fifth review before padding 218 147\n",
            "First review [1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]\n",
            "First label 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Preprocess data**\n",
        "If RNN is trained on one sentence at a time, one can have sentences of varying lengths. However, it can be sometimes be advantageous to train inputs in batches. When doing so with RNNs, our input tensors need to be of the same length/dimensions. Thus, let's pad our sentences."
      ],
      "metadata": {
        "id": "AxiaMXaV2RWl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = sequence.pad_sequences(X_train, maxlen=max_review_length)\n",
        "X_test = sequence.pad_sequences(X_test, maxlen=max_review_length)\n",
        "print('Length of first and fifth review after padding', len(X_train[0]) ,len(X_train[4]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Iy6d7UK2Uq9",
        "outputId": "90f5f3d0-5013-4dc9-97f1-e89f568ccc49"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of first and fifth review after padding 500 500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Classification using CNN**\n",
        "Text can be thought of as 1-dimensional sequence (a single, long vector) and we can apply 1D Convolutions over a set of word embeddings.\n",
        "**Exercise**\n",
        "Fit a 1D convolution with 200 filters, kernel size 3, followed by a feed-forward layer of 250 nodes, and ReLU and Sigmoid activations as appropriate. You can add the embedding function to your model using the following command: model.add(Embedding(vocabulary_size, embedding_dim, input_length=max_review_length))\n",
        "\n",
        "Evaluate the CNN"
      ],
      "metadata": {
        "id": "9FrVP1nc5eln"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# your code here\n",
        "model = Sequential()\n",
        "nb_ffl_node = 250\n",
        "embedding_dim = 100\n",
        "model.add(Embedding(vocabulary_size, embedding_dim, input_length = max_review_length))\n",
        "conv1 = Conv1D(\n",
        "      filters=200,\n",
        "      kernel_size=3,\n",
        "      padding=\"valid\",\n",
        "      activation='relu')\n",
        "model.add(conv1)\n",
        "model.add(MaxPooling1D())\n",
        "model.add(Flatten())\n",
        "fcl1 = Dense(units = nb_ffl_node, activation = 'sigmoid')\n",
        "model.add(fcl1)\n",
        "fcl2 = Dense(units = 1, activation = 'sigmoid')\n",
        "model.add(fcl2)\n"
      ],
      "metadata": {
        "id": "W8gHYDzj791L"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer = 'Adam', loss='BinaryCrossentropy', metrics = 'accuracy')\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3twJQm7dkoXz",
        "outputId": "ace362be-b664-449a-bf06-6ce96e20f4ba"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 500, 100)          1000000   \n",
            "                                                                 \n",
            " conv1d (Conv1D)             (None, 498, 200)          60200     \n",
            "                                                                 \n",
            " max_pooling1d (MaxPooling1D  (None, 249, 200)         0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 49800)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 250)               12450250  \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 251       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 13,510,701\n",
            "Trainable params: 13,510,701\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x=X_train, y=y_train, batch_size=20, epochs=4) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kq2v5BsRk2R0",
        "outputId": "361b9414-fc2b-47fd-abca-4cc2326dac28"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/4\n",
            "1250/1250 [==============================] - 11s 9ms/step - loss: 0.2670 - accuracy: 0.8894\n",
            "Epoch 2/4\n",
            "1250/1250 [==============================] - 11s 9ms/step - loss: 0.1265 - accuracy: 0.9530\n",
            "Epoch 3/4\n",
            "1250/1250 [==============================] - 11s 9ms/step - loss: 0.0445 - accuracy: 0.9853\n",
            "Epoch 4/4\n",
            "1250/1250 [==============================] - 11s 9ms/step - loss: 0.0253 - accuracy: 0.9910\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff88b8f60d0>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(x=X_test, y=y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4KsKB1bJlH3I",
        "outputId": "db7b0dd9-8b4f-4b58-e565-38beb3819427"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "782/782 [==============================] - 4s 4ms/step - loss: 0.5386 - accuracy: 0.8741\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.538589358329773, 0.8741199970245361]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Now, we will built a vanilla recurrent neural network RNN inorder to model the time dependencies. Configures an RNN as following:"
      ],
      "metadata": {
        "id": "8B6zkqASAXdR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# %your code here\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Embedding(vocabulary_size, embedding_dim, input_length = max_review_length))\n",
        "\n",
        "model.add(SimpleRNN(units=100))\n",
        "model.add(Dense(1,activation='sigmoid'))"
      ],
      "metadata": {
        "id": "w2tOGkqZA5Px"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer = 'Adam', loss='BinaryCrossentropy', metrics = 'accuracy')\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OSd8LAE5m889",
        "outputId": "66f5782b-8770-4379-c195-2f8445949a74"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (None, 500, 100)          1000000   \n",
            "                                                                 \n",
            " simple_rnn (SimpleRNN)      (None, 100)               20100     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 101       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,020,201\n",
            "Trainable params: 1,020,201\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x=X_train, y=y_train, batch_size=20, epochs=4) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "Ni2Q0B2QnBBe",
        "outputId": "988712b1-537c-49aa-caee-33bc790735c1"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/4\n",
            "  24/1250 [..............................] - ETA: 7:16 - loss: 0.6985 - accuracy: 0.5292"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-ac78cf042d00>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1214\u001b[0m                 _r=1):\n\u001b[1;32m   1215\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1216\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1217\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    908\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 910\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    940\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    943\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3129\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3130\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3131\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3133\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1958\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1959\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1960\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1961\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1962\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    601\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 603\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    604\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 59\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     60\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(x=X_test, y=y_test)"
      ],
      "metadata": {
        "id": "LJlq4NYLnGm7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In order to handle long sequences, LSTM proposes new 'forget gate' capable to forgot the un-necessary informations and keep the informative ones only. To make it a fair comparison to the SimpleRNN, let's start with the same architecture hyper-parameters (e.g., number of hidden nodes, epochs, and batch size). Then, experiment with increasing the number of nodes, stacking multiple layers, applying dropouts etc. Check the number of parameters that this model entails."
      ],
      "metadata": {
        "id": "tM6wEAsjBPVz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# %your code here\n",
        "embedding_dim = 100\n",
        "dense = Dense(1, activation='sigmoid')\n",
        "embedding = Embedding(vocabulary_size, embedding_dim, input_length=max_review_length)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(embedding)\n",
        "model.add(LSTM(100))\n",
        "model.add(dense)\n",
        "model.compile(optimizer='adam', loss='BinaryCrossentropy', metrics = 'accuracy')\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "Csntm_DUCBw_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6513559b-91ee-45d0-ecae-86ebc9a60711"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_2 (Embedding)     (None, 500, 100)          1000000   \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 100)               80400     \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 101       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,080,501\n",
            "Trainable params: 1,080,501\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x=X_train, y=y_train, batch_size=20, epochs=4) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DE1wbJC4vUxU",
        "outputId": "2ca2cb1b-cfaf-482e-fa92-d519f4b247a7"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/4\n",
            "1250/1250 [==============================] - 28s 21ms/step - loss: 0.4889 - accuracy: 0.7676\n",
            "Epoch 2/4\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.3336 - accuracy: 0.8603\n",
            "Epoch 3/4\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.2565 - accuracy: 0.9024\n",
            "Epoch 4/4\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.2145 - accuracy: 0.9194\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff88feaab50>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(x=X_test, y=y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sPFO98W5vXbU",
        "outputId": "43297b50-df8d-4ce2-d33b-2f6059f10858"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "782/782 [==============================] - 8s 10ms/step - loss: 0.3716 - accuracy: 0.8625\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.37157565355300903, 0.8625199794769287]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CNN+LSTM**\n",
        "\n",
        "CNNs are good at learning spatial features, and sentences can be thought of as 1-D spatial vectors (dimensionality is determined by the number of words in the sentence). We apply an LSTM over the features learned by the CNN (after a maxpooling layer). This leverages the power of CNNs and LSTMs combined! We expect the CNN to be able to pick out invariant features across the 1-D spatial structure (i.e., sentence) that characterize good and bad sentiment. This learned spatial features may then be learned as sequences by an LSTM layer, and the final classification can be made via a feed-forward connection to a single node."
      ],
      "metadata": {
        "id": "YQaiYZ2eCU_I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#CNN + LSTM\n",
        "embedding_dim = 100\n",
        "dense = Dense(1, activation='sigmoid')\n",
        "conv1 = Conv1D(filters=200, kernel_size=3, padding=\"same\", activation='relu')\n",
        "embedding = Embedding(vocabulary_size, embedding_dim, input_length=max_review_length)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(embedding)\n",
        "model.add(conv1)\n",
        "model.add(MaxPooling1D(2))\n",
        "model.add(LSTM(100))\n",
        "model.add(dense)\n",
        "model.compile(optimizer='adam', loss='BinaryCrossentropy', metrics = 'accuracy')\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HnhMMTIOCiwy",
        "outputId": "1924dbf3-6fd9-4e88-fc11-c8a3ef3347fc"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_3 (Embedding)     (None, 500, 100)          1000000   \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 500, 200)          60200     \n",
            "                                                                 \n",
            " max_pooling1d_1 (MaxPooling  (None, 250, 200)         0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 100)               120400    \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 1)                 101       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,180,701\n",
            "Trainable params: 1,180,701\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x=X_train, y=y_train, batch_size=20, epochs=4) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dcfUgMninbxL",
        "outputId": "44038bfe-23d3-4b97-e399-78d9a5f188d4"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/4\n",
            "1250/1250 [==============================] - 20s 15ms/step - loss: 0.4286 - accuracy: 0.7978\n",
            "Epoch 2/4\n",
            "1250/1250 [==============================] - 18s 15ms/step - loss: 0.2199 - accuracy: 0.9144\n",
            "Epoch 3/4\n",
            "1250/1250 [==============================] - 18s 14ms/step - loss: 0.1394 - accuracy: 0.9505\n",
            "Epoch 4/4\n",
            "1250/1250 [==============================] - 18s 14ms/step - loss: 0.0843 - accuracy: 0.9710\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff88e137c10>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(x=X_test, y=y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vJ3qO00ing-s",
        "outputId": "903f2507-58cd-424f-a938-9c33d682e2c1"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "782/782 [==============================] - 7s 8ms/step - loss: 0.3733 - accuracy: 0.8778\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3733188211917877, 0.8777999877929688]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercice 2**\n",
        "\n",
        "Now, we investigate facial expression from facial landmarks. Data come from Cohn-Kanade Extended (CK+) dataset that consists of\n",
        "327 image sequences performed by 118 subjects with\n",
        "seven emotion labels: anger, contempt, disgust, fear, happiness, sadness, and surprise. Each sequence contains the\n",
        "two first temporal phases of the expression, i.e., neutral\n",
        "and onset (with apex frames).\n",
        "\n",
        "We begin by importing the necessary packages.\n"
      ],
      "metadata": {
        "id": "YkbFyau1BZr_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "3q0p3q4bBV2e"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import scipy.io\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download the sequences data using the following link:\n",
        "https://drive.google.com/file/d/1z1782inlLuiX51Mea3sK6oawUhZZKtXg/view?usp=sharing\n",
        "\n",
        "Download the corresponding sequences labels via the next link: \n",
        "https://drive.google.com/file/d/1ySxGbb5IOzD5pYNcMlX90WToV4msCC59/view?usp=sharing\n",
        "\n",
        "Save the two resulting '.mat' files into your hard disk\n"
      ],
      "metadata": {
        "id": "a5lojYadKaz9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "#matrice = scipy.io.loadmat('C:/Users/remyd/Documents/Centrale/G3/ML en action/sequences_ckp.mat')"
      ],
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": "OK"
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "id": "3RUMCD8CLjww",
        "outputId": "9b5fd262-6524-412c-a5a2-193c367c5717"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-5c4f7eb5-d8c7-45a5-b2db-387b1f57792f\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-5c4f7eb5-d8c7-45a5-b2db-387b1f57792f\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving labels_ckp.mat to labels_ckp (2).mat\n",
            "Saving sequencesckp.mat to sequencesckp (2).mat\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "matrice = scipy.io.loadmat('sequencesckp.mat')\n",
        "TabSequences = matrice['sequences'][0]\n",
        "\n",
        "labels = scipy.io.loadmat('labels_ckp.mat')\n",
        "TabLabels = labels['labels'][0]\n"
      ],
      "metadata": {
        "id": "h2NSrhFjj4Jw"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TabSequences is the variable with the 327 sequences, each sequence is of size (49,n,2), where n is the number of frames (faces) of the sequence and the number of facial landmarks is 49, each of size 2 (x and y). Thus the first sequence for example (TabSequences[0]) is of size (49,11,2) with 11 faces, each face has 49 landmarks and each landmark has two coordinates (x and y).\n",
        "\n",
        "TabLabels is the variables of the labels (327 labels).\n",
        "\n",
        "Plot the first face of the first frame"
      ],
      "metadata": {
        "id": "E1Gi1xq0qKh3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Sequence1 = TabSequences[0]\n",
        "visage1 = Sequence1[:,0,:]\n",
        "plt.plot(visage1[:,0],visage1[:,1],'x' )\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "6sKQWPUZomJi",
        "outputId": "c3dbcf2f-be44-4e5e-b504-59740be0ef39"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAXhklEQVR4nO3df6xcZZ3H8fcXqGDibsHe+0ftbS2ZIgRNaeXS1su6NXVFhN0tbtwNdovgEttmaYrBuAj/iJvVrImUXdIslS6/a0WiJiKSULS1Em5suaXlSqGNdwRKawP3YqmisVngu3/MM2Xur7kznXNmznnO55VMOuc5M2ee0zP3O8/5Ps95jrk7IiISl1M6XQEREUmegruISIQU3EVEIqTgLiISIQV3EZEIndbpCgB0dXX53LlzO10NEZFc2b1794i7d0+0LhPBfe7cuQwMDHS6GiIiuWJmL022TmkZEZEIKbiLiERIwV1EJEIK7iIiEVJwFxGJkIK7FMrGHWX6yyOjyvrLI2zcUc70tkWapeAuhTK/Zzprt+w5EYT7yyOs3bKH+T3TM71tkWZZFqb87e3tdY1zl3apBt2Vi+eweedBNqxYSF+pK/Pb3rijzPye6aO2118eYfDQMdYsLSXyGZIvZrbb3XsnWqeWuxROX6mLlYvncPu2IVYunpNY8E172zozkGYouEvh9JdH2LzzIOuWzWPzzoPj8uRZ3XZfqYsNKxaydsse1m89wNotexI9M5C4KLhLoVRbuxtWLOSGS849ESyTCMJpbrsqzTMDiYuCuxTK4KFjo1q71dbw4KFjmd52VZpnBhKXKTtUzewM4BfA6VQmGvu+u3/VzO4FlgLVb+417r7XzAz4b+Ay4E+h/Ol6n6EOVamljsOJ1Z4Z9JW6xi1L8bTaoXocWObuFwALgEvNbElY92V3XxAee0PZp4BzwmMVcEdr1ZeiUcfhxNpxZiDxmHLKX6807d8Ii9PCo15zfzlwf3jfL83sTDOb6e5HWq6tFEJtx2EaQwrzaqKzlr5SV+H/X2RiDeXczexUM9sLvAo87u47w6qvm9mgmd1mZqeHslnAyzVvPxTKxm5zlZkNmNnA8PBwC7sgMVLHYfvoyto4NRTc3f0td18A9ACLzOxDwE3AecBFwHuBG5v5YHe/09173b23u3vCG4lIganjsH2UBotTU6Nl3P11YDtwqbsf8YrjwD3AovCyw8Dsmrf1hDKRhrRjSKG8Q+Pn4zRlcDezbjM7Mzx/N/AJYL+ZzQxlBlwBPBve8jDwOatYAhxTvl2aoY7D9lMaLD6N3EN1JnCfmZ1K5cfgIXd/xMy2mVk3YMBeYE14/aNUhkEOURkK+fnkqy0xU8dh+41Ngy0pzdD/d841MlpmEFg4QfmySV7vwHWtV01E2mHsePklpRlKzURAV6iKFJzSYHHSlL8iIjmlKX8ldRorLZItCu6SCI2VFsmWRkbLiExJUwaIZIta7pIYjZUWyQ4Fd0lMkacMKHqfQ9H3P4sU3CURWZwy4Jp7drHpidHBZdMTZa65Z1fin/XSa39k9QO7R/U5rH5gNy+99sfEPyuL1OeSPQrukogsjpW+eN4MvvGT/ScC/KYnynzjJ/u5eN6MxD/r7y54HwCrH9jN+q0HWP3A7lHlsdP8NNmjce4StWpAv2juWTz14lFuvvw8vvDRdO7m1F8e4V/ufYo//9/bnDHtFO6+5qLCBbf1Ww9w+7Yh1i2bxw2XnNvp6kRP49ylsL7w0RIXzT2LXS8e5aK5Z6UW2NulnammZhW5zyWLFNwlapueKPPUi0dZFFruYwNjUqo59mmnnsK6ZfOYduopo3LwSWlnqqkZWexzKTqNc5doVQNfNRVTXQYSb8H/+JnfAvDtqy48MfnW6gd28+NnfptoaqZa72/8ZD+P73sl9VRTo+r1uRQtNZUVyrlLtK65ZxcXz5sxKvBteqLMk0Ovce/nF9V5Z/M27igzv2f6qEDWXx5h8NCxCacwbtU/bexnVzgjeWhNX+Lbl3yol3NXcBfJmXZ2Eku2qUNVckMXw9RXm2p6aE0fN19+3qgcvEiVgrtkii6Gqe/JoddGtdS/8NESN19+Hk8OvdbhmknWKC0jmVMN6JqATKQ+pWUkVzQBWfsoDRYvBXfJHF0M0z5Kg8VL49wlU3Sz5vbSPPzxUstdMiWLE5BNJe+pDaXB4qTgLpmyZmlpXHDpK3WlciFQUvKe2lAaLE4K7hK9tFvWeZ7uVnPCxEvBXaLXjpZ1XlMbeUyDSWM0zl0KIe2x82luv93z1kh+aJy7FF6aLeu0Uxt5z+lLZyi4SyGk2WmYdmojzzl96RyNc5fopT12fqLUSF+pK9HgW3vmsW7ZPAV2mZJa7hK9GDoNNVxRmqUOVZGMG3vmMXZZiksdqiI5FsOZh7SfWu4iIjmllruISMEouIuIREjBXUQkQgruIiIRUnAXEYmQgruISISmDO5mdoaZ7TKzZ8xsn5l9LZSfbWY7zWzIzL5nZu8K5aeH5aGwfm66uyAiImM10nI/Dixz9wuABcClZrYE+CZwm7vPA44C14bXXwscDeW3hdeJiEgbTRncveKNsDgtPBxYBnw/lN8HXBGeLw/LhPUfNzNLrMYiIjKlhnLuZnaqme0FXgUeB8rA6+7+ZnjJIWBWeD4LeBkgrD8GzJhgm6vMbMDMBoaHh1vbCxERGaWh4O7ub7n7AqAHWASc1+oHu/ud7t7r7r3d3d2tbk6kY9K+R6vIyWhqtIy7vw5sBz4CnGlm1fnge4DD4flhYDZAWD8deC2R2opkkO6UJFnUyGiZbjM7Mzx/N/AJ4HkqQf4z4WVXAz8Kzx8Oy4T12zwLs5OJ1Eiyta07JUkWNdJynwlsN7NB4CngcXd/BLgRuMHMhqjk1O8Kr78LmBHKbwC+kny1RVqTdGu71Xu0KrUjSZvyNnvuPggsnKD8N1Ty72PL/wz8YyK1E0lJbWt75eI5bN55sKXW9tg7JS0pzWhqW9Ufm4luyCFyMnQPVSmspO5LmsQ9WpP+sRHR9ANSWEndlzSpOyW1mtoRqaWWuxRSEq3tqjVLS+PK+kpdTW+n1dSOSC213CV3kuh8zNp9SWt/bG645NwTKZqTPZsQUXCX3ElipMuapaVxreK+UteErfB2yNqPjeSfbpAtuVQN6EXvfNy4o8z8numj9r2/PMLgoWMd+6GS9tENsiU66nys0NWxMhl1qEouqfOxQkMoZTJquUvuqPNxNJ3FyEQU3CV31Pk4WlLj9SUu6lAVybGx4/XHLkvc1KEqEimdxchk1HIXEckptdxFRApGwV2kBZqHXbJKwV2kBbqISLJKFzGJtEAXEUlWqeUu0iJdRCRZpOAu0iJdRCRZpOAu0gJNhSBZpeAu0gJdRCRZpYuYRERyShcxiYgUjIK7iEiEFNxFRCKk4C4iEiEFdxGRCCm4i4hESMFdRCRCCu4iIhFScBcRiZCCu4hIhBTcRUQipOAuIhIhBXcRkQgpuIuIREjBXUQkQgruIiIRmjK4m9lsM9tuZs+Z2T4zuz6U32Jmh81sb3hcVvOem8xsyMwOmNkn09wBEREZ77QGXvMm8CV3f9rM/gLYbWaPh3W3ufu3al9sZucDVwIfBN4H/NTMPuDubyVZcRERmdyULXd3P+LuT4fnfwCeB2bVecty4EF3P+7uLwBDwKIkKiuSFRt3lMfdBLu/PMLGHeUO1UhktKZy7mY2F1gI7AxFa81s0MzuNrOzQtks4OWatx1igh8DM1tlZgNmNjA8PNx0xUU6aX7PdNZu2XMiwPeXR1i7ZQ/ze6Z3uGYiFQ0HdzN7D/AD4Ivu/nvgDqAELACOALc288Hufqe797p7b3d3dzNvFem4vlIXG1YsZO2WPazfeoC1W/awYcVC+kpdna6aCNBgcDezaVQC+3fc/YcA7v6Ku7/l7m8Dm3gn9XIYmF3z9p5QJhKVvlIXKxfP4fZtQ6xcPEeBXTKlkdEyBtwFPO/u62vKZ9a87NPAs+H5w8CVZna6mZ0NnAPsSq7KItnQXx5h886DrFs2j807D47LwYt0UiOjZS4GrgJ+ZWZ7Q9nNwGfNbAHgwIvAagB332dmDwHPURlpc51Gykhsqjn2aipmSWmGUjOSKebuna4Dvb29PjAw0OlqiDRs444y83umjwrk/eURBg8dY83SUgdrJkViZrvdvXfCdQruIiL5VC+4a/oBEZEIKbiLiERIwV1EJEIK7iIiEVJwFxGJkIK7iEiEFNxFRCKk4C4iEiEFdxGRCCm4i4hESMFdRCRCCu4iIhFScBcRiZCCu4hIhBTcRUQipOAuIhIhBXcRkQgpuIuIREjBXaQJG3eU6S+PjCrrL4+wcUe5QzUSmZiCu0gT5vdMZ+2WPScCfH95hLVb9jC/Z3qHayYy2mmdroBInvSVutiwYiFrt+xh5eI5bN55kA0rFtJX6up01URGUctdpEl9pS5WLp7D7duGWLl4jgK7ZJKCu0iT+ssjbN55kHXL5rF558FxOXiRLFBwF2lCNce+YcVCbrjk3BMpGgV4yRoFd5EmDB46NirHXs3BDx461uGaiYxm7t7pOtDb2+sDAwOdroaISK6Y2W53751onVruIiIRUnAXEYmQgruISIQU3EVEIqTgnjNpzW2iOVNE4qLgnjNpzW2iOVNE4qKhkDlUDbxJz22S1nZFJB0aChmZtOY20ZwpIvFQcM+htOY20ZwpcjLUX5NNCu45k9bcJmlsV3/0xZBGf42+O61TcE9Z0l/StOY2SWO76qQthto57tdvPXCikdBKWk/fnQS4e90HMBvYDjwH7AOuD+XvBR4Hfh3+PSuUG3A7MAQMAh+e6jMuvPBCj9WTQ8O+8N+3+pNDwxMux666v7c+tr9Q+11Etz62399/4yN+62P7E9mevjtTAwZ8krjaSMv9TeBL7n4+sAS4zszOB74C/MzdzwF+FpYBPgWcEx6rgDta+/nJtzRaNXmiTtpsSSvdkUZ/jb47rZkyuLv7EXd/Ojz/A/A8MAtYDtwXXnYfcEV4vhy4P/yw/BI408xmJl7zHCnyl1SdtNmSRrojzX4gfXdaMFmTfqIHMBc4CPwl8HpNuVWXgUeAv6pZ9zOgd4JtrQIGgIE5c+ake+7SYUU9vSx6Siqrkv4+3vHzoXHbeHJo2O/4+VDLddR3pz7qpGWaCezvAXYD/xCWXx+z/qg3EdxrH8q5xymNP3pJRtL58aTpu9OYesG9oStUzWxaCNqPufv6UHYA+Ji7Hwlpl5+7+7lm9u3w/LtjXzfZ9mO+QnXjjjLze6aPSsX0l0cYPHSMNUtLHayZFJWuRI5HS1eompkBdwHPVwN78DBwdXh+NfCjmvLPWcUS4Fi9wB67NUtL4/5w+kpdCuw5EtOY6yLfAzam49iIRkbLXAxcBSwzs73hcRnwn8AnzOzXwN+EZYBHgd9QGQq5CfjX5Kst0j4xjbku8j1gYzqOjdDEYSINUCojDrEdR00cFpG0Ty2LduraqCIPZ41JkY6jgnvOpH1qWbRT10ZpzHUcCnUcJxtG085HzEMh05D2uPmijsufTJGHs8YkxuNIi9MPSMakfWpZpFPXRhS5EzImRTuO6lDNobQ7hWLrdBKJlTpUI5L2OOUij4OWxqjTPR8U3HMm7VPLop26SvPS7nTXj0cylJYRkaalmbqrPXvsK3WNW5Z31EvLnNbuyohI/tV2uq9bNi/RoFt7DwT1+5w8pWVEpGlpjxfXiK3WKbiLSFPa0eleqIuNUqLgLiJNSbvTXSO2kqEOVRHJFN0DoXH1OlQV3EVEckoXMYmIFEwug7suchARqS+XwV3T0oqI1JfLi5h0kYOISH25bLmDLnIQEaknt8FdFzmIiEwul8FdFzmIiNSXy+CuaWnjpZFQIsnIZXBfs7Q0LsfeV+rS1WsR0EgokWTkMrhLvGpHQq3feqBw83jrzEWSouAumVPkkVA6c5Gk5HKcu8Rt7EioJaUZhQnwuoZDkqKWu2SKRkIV+8xFkqPgLpmikVC6hqMI2tG3ouAumVL0kVA6cymGdvStaD53kQzRjSqKoxrQW+lb0XzuJ6nIw9KKvO+dVPQzlyJJu29Fwb2OIg9LK/K+i7RD2n0rSstMIYlTp7wq8r6LpKm2b6Wv1DVuuVFKy7SgyMPSirzvRaIUXPu1Y1SYgvsUOjUsLQt/cBqSVwxKwbVfO/pWFNzr6OSwtE7/wWlIXnEUfT6fWCnnXkenh6V1Mufd6X2X9lu/9QC3bxti3bJ53HDJuZ2ujjSgXs5dwT3j9Acn7aDO83xSh2pOKect7VD0FFwW+rfSMGVwN7O7zexVM3u2puwWMztsZnvD47KadTeZ2ZCZHTCzT6ZV8dgV/Q9O2qfo8/l0un8rLVOmZczsr4E3gPvd/UOh7BbgDXf/1pjXng98F1gEvA/4KfABd3+r3mcoLTOect5SFFn4ruc1LdVSWsbdfwH8rsHPWg486O7H3f0FYIhKoJcm6TJ0KYostJxjvKajlZz7WjMbDGmbs0LZLODlmtccCmXjmNkqMxsws4Hh4eEWqiEieZaFoZgx9m+dbHC/AygBC4AjwK3NbsDd73T3Xnfv7e7uPslqiEgMOtlyjrV/66SCu7u/4u5vufvbwCbeSb0cBmbXvLQnlImITKqTLedYO5RP6h6qZjbT3Y+ExU8D1ZE0DwNbzGw9lQ7Vc4BdLddSRKI1dtKsJaUZbU3NTNSP1Vfqyn3efcrgbmbfBT4GdJnZIeCrwMfMbAHgwIvAagB332dmDwHPAW8C1001UkZEiq1eyznvAbaTdIWqiEhO6QpVEZGCUXAXEYmQgruISIQU3EVEIqTgLiISoUyMljGzYeClk3x7F5DvS8laU/T9B/0faP+Lu//vd/cJL/HPRHBvhZkNTDYUqAiKvv+g/wPtf7H3fzJKy4iIREjBXUQkQjEE9zs7XYEOK/r+g/4PtP8yTu5z7iIiMl4MLXcRERlDwV1EJEKZD+5mNtvMtpvZc2a2z8yuD+W3mNlhM9sbHpfVvOcmMxsyswNm9snO1b51ZnaGme0ys2fC/n8tlJ9tZjvDfn7PzN4Vyk8Py0Nh/dxO1r9Vdfb/XjN7oeb4LwjlZma3h/0fNLMPd3YPkmFmp5rZHjN7JCwX4vhXTbD/hTr+JyPzwZ3KvPBfcvfzgSXAdWZ2flh3m7svCI9HAcK6K4EPApcC/2Nmp3ai4gk5Dixz9wuo3NbwUjNbAnyTyv7PA44C14bXXwscDeW3hdfl2WT7D/DlmuO/N5R9ispNYs4BVlG5JWQMrgeer1kuyvGvGrv/UKzj37TMB3d3P+LuT4fnf6BygCe86XawHHjQ3Y+7+wvAEO/cBjB3vOKNsDgtPBxYBnw/lN8HXBGeLw/LhPUfNzNrU3UTV2f/J7McuD+875fAmWY2M+16psnMeoDLgf8Ny0ZBjj+M3/8pRHf8T1bmg3utcIq5ENgZitaGU6+7zeysUDYLeLnmbYeo/2OQeeGUdC/wKvA4UAZed/c3w0tq9/HE/of1x4AZ7a1xssbuv7tXj//Xw/G/zcxOD2XRHX/gv4B/A94OyzMo0PFn/P5XFeX4n5TcBHczew/wA+CL7v57KqdbJSqn6keAWztYvVSFm5EvoHLD8UXAeR2uUluN3X8z+xBwE5X/h4uA9wI3drCKqTGzvwVedffdna5LJ9TZ/0Ic/1bkIrib2TQqgf077v5DAHd/JfzRvw1s4p3Uy2Fgds3be0JZ7rn768B24CNUTjer98Ct3ccT+x/WTwdea3NVU1Gz/5eGdJ27+3HgHuI9/hcDf29mLwIPUknH/DfFOf7j9t/MNhfo+J+0zAf3kC+8C3je3dfXlNfm0T4NPBuePwxcGUYNnE2lY2VXu+qbNDPrNrMzw/N3A5+g0u+wHfhMeNnVwI/C84fDMmH9Ns/xlWqT7P/+6vEP348rGH38PxdGTSwBjrn7kQ5UPRHufpO797j7XCoDBba5+z9TkOM/yf6vLMrxb8VpU7+k4y4GrgJ+FfKuADcDnw3Dnxx4EVgN4O77zOwh4DkqI22uc/e32l7r5MwE7gsjfk4BHnL3R8zsOeBBM/sPYA+VH0DCvw+Y2RDwOyp/EHk22f5vM7NuwIC9wJrw+keBy6h0pP8J+HwH6twON1KM4z+Z7xT8+E9J0w+IiEQo82kZERFpnoK7iEiEFNxFRCKk4C4iEiEFdxGRCCm4i4hESMFdRCRC/w//NUnd/87Q1AAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Pre-process data**\n",
        "Put the landmark coordinates into one dimension (98) then pad the sequences to the maximum size of them (maximum number of frames). Is this padding mandatory or only advantageous if we use CNN based classifier (see exercise 1) and LSTM-based one."
      ],
      "metadata": {
        "id": "9-91DMGMv-vy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(0,326):\n",
        "  Sequence = TabSequences[i]\n",
        "  SeqReshaped = Sequence1.reshape(98,11)\n",
        "#sequence\n",
        "#tf.keras.preprocessing.sequence.pad_sequences(sequence)\n",
        "\n",
        "Sequence1 = TabSequences[0]\n",
        "SeqReshaped = Sequence1.reshape(98,11)\n",
        "SeqReReshaped = SeqReshaped.reshape(49,11,2)\n",
        "visage1 = SeqReReshaped[:,0,:]\n",
        "plt.plot(visage1[:,0],visage1[:,1],'x' )\n",
        "plt.show()\n",
        "SeqReshaped.shape\n",
        "#X_train = sequence.pad_sequences(X_train, maxlen=max_review_length)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "id": "GSD2WW1JwB37",
        "outputId": "4efed8eb-b66e-4561-d2e8-eadd359fe69a"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(98, 11)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Classification using CNN**\n",
        "Perform classification using a 1D-CNN the 2D-CNN with the same parameters used in exercise 1 (keep the same parameters for both convolutions for fair comparison). "
      ],
      "metadata": {
        "id": "qFETk0YOt5sN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1D-CNN model here\n",
        "# your code here\n",
        "max_review_length = 6958\n",
        "model = Sequential()\n",
        "input = Input(shape=(max_review_length, 1))\n",
        "conv1 = Conv1D(filters=200, kernel_size=3, padding=\"same\", activation='relu')\n",
        "dense = Dense(250, activation='sigmoid')\n",
        "dense_1 = Dense(7, activation='softmax')\n",
        "\n",
        "model = Sequential()\n",
        "#model.add(Embedding(vocabulary_size, embedding_dim, input_length=l_review_length))\n",
        "model.add(input)\n",
        "model.add(conv1)\n",
        "model.add(MaxPooling1D(2))\n",
        "model.add(Flatten())\n",
        "model.add(dense)\n",
        "model.add(dense_1)\n",
        "model.compile(optimizer='adam', loss='CategoricalCrossentropy', metrics = 'accuracy')\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "7f0aHQVFIfYK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf528555-4c6f-452d-94b4-8800db5cee5d"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_2 (Conv1D)           (None, 6958, 200)         800       \n",
            "                                                                 \n",
            " max_pooling1d_2 (MaxPooling  (None, 3479, 200)        0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 695800)            0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 250)               173950250 \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 7)                 1757      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 173,952,807\n",
            "Trainable params: 173,952,807\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "s = 0\n",
        "for i in range(0,327):\n",
        "  max = TabSequences[i].shape[1]\n",
        "  if s < max : \n",
        "    s = max\n",
        "\n",
        "print (s)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fr1z67RiWGvk",
        "outputId": "abe008bf-f6dd-476a-c834-a7d8a806116e"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "71\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "l = []\n",
        "for i in range(0,327):\n",
        "  shape = TabSequences[i].shape[1]\n",
        "  l1 = []\n",
        "  for j in range (TabSequences[i].shape[0]):\n",
        "    l1.append(np.concatenate([TabSequences[i][j],np.array(TabSequences[i][j][shape-1].tolist()*(s-shape)).reshape(s-shape,2)]))\n",
        "  l.append(l1)\n",
        "l = np.array(l)\n",
        "l = l.reshape(327, 49*71*2)"
      ],
      "metadata": {
        "id": "t_ppmN5_XmR-"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TabLabels1 = TabLabels - 1\n",
        "TabLabels2 = tf.keras.utils.to_categorical(TabLabels1)\n",
        "X_train, X_test, y_train, y_test = train_test_split(l, TabLabels2, test_size=0.1, random_state=42)\n",
        "model.fit(x=X_train, y=y_train, batch_size=20, epochs=20) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jyyhml6niJGf",
        "outputId": "df23a5b6-b595-43df-bc57-7daf514eecbc"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "15/15 [==============================] - 1s 65ms/step - loss: 2.1711 - accuracy: 0.2517\n",
            "Epoch 2/20\n",
            "15/15 [==============================] - 1s 63ms/step - loss: 1.8290 - accuracy: 0.2279\n",
            "Epoch 3/20\n",
            "15/15 [==============================] - 1s 63ms/step - loss: 1.8194 - accuracy: 0.2517\n",
            "Epoch 4/20\n",
            "15/15 [==============================] - 1s 63ms/step - loss: 1.8228 - accuracy: 0.2381\n",
            "Epoch 5/20\n",
            "15/15 [==============================] - 1s 63ms/step - loss: 1.8153 - accuracy: 0.2653\n",
            "Epoch 6/20\n",
            "15/15 [==============================] - 1s 63ms/step - loss: 1.8120 - accuracy: 0.2653\n",
            "Epoch 7/20\n",
            "15/15 [==============================] - 1s 63ms/step - loss: 1.8142 - accuracy: 0.2653\n",
            "Epoch 8/20\n",
            "15/15 [==============================] - 1s 63ms/step - loss: 1.8129 - accuracy: 0.2517\n",
            "Epoch 9/20\n",
            "15/15 [==============================] - 1s 62ms/step - loss: 1.8388 - accuracy: 0.2551\n",
            "Epoch 10/20\n",
            "15/15 [==============================] - 1s 63ms/step - loss: 1.8263 - accuracy: 0.2347\n",
            "Epoch 11/20\n",
            "15/15 [==============================] - 1s 63ms/step - loss: 1.8191 - accuracy: 0.2347\n",
            "Epoch 12/20\n",
            "15/15 [==============================] - 1s 63ms/step - loss: 1.8131 - accuracy: 0.2653\n",
            "Epoch 13/20\n",
            "15/15 [==============================] - 1s 63ms/step - loss: 1.8122 - accuracy: 0.2449\n",
            "Epoch 14/20\n",
            "15/15 [==============================] - 1s 62ms/step - loss: 1.8252 - accuracy: 0.2653\n",
            "Epoch 15/20\n",
            "15/15 [==============================] - 1s 62ms/step - loss: 1.8241 - accuracy: 0.2041\n",
            "Epoch 16/20\n",
            "15/15 [==============================] - 1s 63ms/step - loss: 1.8144 - accuracy: 0.2653\n",
            "Epoch 17/20\n",
            "15/15 [==============================] - 1s 63ms/step - loss: 1.8183 - accuracy: 0.2653\n",
            "Epoch 18/20\n",
            "15/15 [==============================] - 1s 63ms/step - loss: 1.8218 - accuracy: 0.2415\n",
            "Epoch 19/20\n",
            "15/15 [==============================] - 1s 62ms/step - loss: 1.8114 - accuracy: 0.2449\n",
            "Epoch 20/20\n",
            "15/15 [==============================] - 1s 62ms/step - loss: 1.8138 - accuracy: 0.2653\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff889af49d0>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(x=X_test, y=y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9AwG-WZBmvh2",
        "outputId": "e90187dd-6003-4272-da75-cfae79cab280"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 18ms/step - loss: 2.0920 - accuracy: 0.1515\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2.092010974884033, 0.1515151560306549]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2D-CNN model here\n",
        "max_review_length = 6958\n",
        "model = Sequential()\n",
        "input = Input(shape=(98,71, 1))\n",
        "conv2 = Conv2D(filters=200, kernel_size=[3,3], padding=\"same\", activation='relu')\n",
        "dense = Dense(250, activation='sigmoid')\n",
        "dense_1 = Dense(7, activation='softmax')\n",
        "\n",
        "model = Sequential()\n",
        "#model.add(Embedding(vocabulary_size, embedding_dim, input_length=l_review_length))\n",
        "model.add(input)\n",
        "model.add(conv2)\n",
        "model.add(MaxPooling2D())\n",
        "model.add(Flatten())\n",
        "model.add(dense)\n",
        "model.add(dense_1)\n",
        "model.compile(optimizer='adam', loss='CategoricalCrossentropy', metrics = 'accuracy')\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "WY2jLcmwIkZi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f01a8ae-3d9f-4d7a-8ade-ba173d36db22"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 98, 71, 200)       2000      \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 49, 35, 200)      0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 343000)            0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 250)               85750250  \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 7)                 1757      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 85,754,007\n",
            "Trainable params: 85,754,007\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "l = l.reshape(327, 98, 71, 1)\n",
        "X_train, X_test, y_train, y_test = train_test_split(l, TabLabels2, test_size=0.1, random_state=42)\n",
        "model.fit(x=X_train, y=y_train, batch_size=20, epochs=20) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G_UQk6qarack",
        "outputId": "146d0c7e-1c6d-4a54-c43e-4dba1e32a4b8"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "15/15 [==============================] - 1s 40ms/step - loss: 2.0374 - accuracy: 0.2007\n",
            "Epoch 2/20\n",
            "15/15 [==============================] - 0s 33ms/step - loss: 1.8447 - accuracy: 0.2211\n",
            "Epoch 3/20\n",
            "15/15 [==============================] - 1s 34ms/step - loss: 1.8198 - accuracy: 0.2551\n",
            "Epoch 4/20\n",
            "15/15 [==============================] - 1s 34ms/step - loss: 1.8123 - accuracy: 0.2653\n",
            "Epoch 5/20\n",
            "15/15 [==============================] - 1s 34ms/step - loss: 1.8252 - accuracy: 0.2653\n",
            "Epoch 6/20\n",
            "15/15 [==============================] - 1s 34ms/step - loss: 1.8151 - accuracy: 0.2449\n",
            "Epoch 7/20\n",
            "15/15 [==============================] - 0s 33ms/step - loss: 1.8224 - accuracy: 0.2449\n",
            "Epoch 8/20\n",
            "15/15 [==============================] - 1s 34ms/step - loss: 1.8089 - accuracy: 0.2653\n",
            "Epoch 9/20\n",
            "15/15 [==============================] - 1s 34ms/step - loss: 1.8202 - accuracy: 0.2143\n",
            "Epoch 10/20\n",
            "15/15 [==============================] - 0s 33ms/step - loss: 1.8120 - accuracy: 0.2653\n",
            "Epoch 11/20\n",
            "15/15 [==============================] - 0s 33ms/step - loss: 1.8287 - accuracy: 0.2653\n",
            "Epoch 12/20\n",
            "15/15 [==============================] - 1s 33ms/step - loss: 1.8086 - accuracy: 0.2653\n",
            "Epoch 13/20\n",
            "15/15 [==============================] - 1s 34ms/step - loss: 1.8132 - accuracy: 0.2279\n",
            "Epoch 14/20\n",
            "15/15 [==============================] - 0s 33ms/step - loss: 1.8187 - accuracy: 0.2653\n",
            "Epoch 15/20\n",
            "15/15 [==============================] - 1s 34ms/step - loss: 1.8215 - accuracy: 0.2449\n",
            "Epoch 16/20\n",
            "15/15 [==============================] - 1s 33ms/step - loss: 1.8099 - accuracy: 0.2483\n",
            "Epoch 17/20\n",
            "15/15 [==============================] - 1s 34ms/step - loss: 1.8189 - accuracy: 0.2653\n",
            "Epoch 18/20\n",
            "15/15 [==============================] - 1s 34ms/step - loss: 1.8183 - accuracy: 0.2211\n",
            "Epoch 19/20\n",
            "15/15 [==============================] - 1s 34ms/step - loss: 1.8136 - accuracy: 0.2653\n",
            "Epoch 20/20\n",
            "15/15 [==============================] - 1s 34ms/step - loss: 1.8163 - accuracy: 0.2449\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff889332ad0>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(x=X_test, y=y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b3C6201Vs3lI",
        "outputId": "5b90df5a-14ca-4c03-fe27-96afb012d5ec"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 25ms/step - loss: 2.0832 - accuracy: 0.1515\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2.0832412242889404, 0.1515151560306549]"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Classification using RNN**\n",
        "Use an RNN model (you can use the one proposed in exercice 1) to perform classifciation based on a vanilla RNN"
      ],
      "metadata": {
        "id": "BL7ebKm5Imc6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# RNN model here\n",
        "max_review_length = 6958\n",
        "model = Sequential()\n",
        "input = Input(shape=(max_review_length, 1))\n",
        "dense_1 = Dense(7, activation='softmax')\n",
        "\n",
        "model = Sequential()\n",
        "#model.add(Embedding(vocabulary_size, embedding_dim, input_length=l_review_length))\n",
        "model.add(input)\n",
        "model.add(SimpleRNN(100))\n",
        "model.add(dense_1)\n",
        "model.compile(optimizer='adam', loss='CategoricalCrossentropy', metrics = 'accuracy')\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "SsFCIgKJLDAX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d49ea14-a0d4-401a-a116-ee08a05221f3"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " simple_rnn_1 (SimpleRNN)    (None, 100)               10200     \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 7)                 707       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 10,907\n",
            "Trainable params: 10,907\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "l = l.reshape(327, 49*71*2)\n",
        "X_train, X_test, y_train, y_test = train_test_split(l, TabLabels2, test_size=0.1, random_state=42)\n",
        "model.fit(x=X_train, y=y_train, batch_size=20, epochs=5) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "id": "xTraDEl0tx-q",
        "outputId": "dc6d4e0b-cd32-463e-e14a-ecd61ca1ef5b"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            " 4/15 [=======>......................] - ETA: 57s - loss: 3.9565 - accuracy: 0.0375 "
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-c384f4c777b2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m327\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m49\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m71\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTabLabels2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1214\u001b[0m                 _r=1):\n\u001b[1;32m   1215\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1216\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1217\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    908\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 910\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    940\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    943\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3129\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3130\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3131\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3133\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1958\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1959\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1960\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1961\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1962\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    601\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 603\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    604\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 59\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     60\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**LSTM-based classification**\n",
        "Perform the classification using a LSTM (you can use the one proposed in exercice 1)"
      ],
      "metadata": {
        "id": "W6sNiNcPLFhb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# LSTM model here\n",
        "max_review_length = 6958\n",
        "dense = Dense(7, activation='softmax')\n",
        "input = Input(shape=(max_review_length, 1))\n",
        "\n",
        "model = Sequential()\n",
        "model.add(input)\n",
        "model.add(LSTM(100))\n",
        "model.add(dense)\n",
        "model.compile(optimizer='adam', loss='CategoricalCrossentropy', metrics = 'accuracy')\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "EpYtjvTvLYIn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f03e187c-84ad-41d6-e95b-ebd6ede73861"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_2 (LSTM)               (None, 100)               40800     \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 7)                 707       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 41,507\n",
            "Trainable params: 41,507\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(l, TabLabels2, test_size=0.1, random_state=42)\n",
        "model.fit(x=X_train, y=y_train, batch_size=20, epochs=5) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fw-P4jJbw-je",
        "outputId": "98eaa985-abfd-459c-998f-91622db2769b"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "15/15 [==============================] - 5s 210ms/step - loss: 1.9200 - accuracy: 0.2653\n",
            "Epoch 2/5\n",
            "15/15 [==============================] - 3s 209ms/step - loss: 1.8297 - accuracy: 0.2415\n",
            "Epoch 3/5\n",
            "15/15 [==============================] - 3s 208ms/step - loss: 1.8026 - accuracy: 0.2891\n",
            "Epoch 4/5\n",
            "15/15 [==============================] - 3s 208ms/step - loss: 1.7931 - accuracy: 0.2653\n",
            "Epoch 5/5\n",
            "15/15 [==============================] - 3s 206ms/step - loss: 1.7963 - accuracy: 0.2959\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff884824c50>"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(x=X_test, y=y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2URCuXD-xEGH",
        "outputId": "776f8d20-5a2f-48a7-8dec-7d77cea030df"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 1s 218ms/step - loss: 2.0146 - accuracy: 0.1515\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2.014601230621338, 0.1515151560306549]"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CNN+LSTM for better classification**\n",
        "Finally perform a classification based on CNN and LSTM to outperform the previous models"
      ],
      "metadata": {
        "id": "98oB9FiQLcXU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# your code here\n",
        "max_review_length = 6958\n",
        "dense = Dense(7, activation='softmax')\n",
        "input = Input(shape=(max_review_length, 1))\n",
        "conv1 = Conv1D(filters=200, kernel_size=3, padding=\"same\", activation='relu')\n",
        "\n",
        "model = Sequential()\n",
        "model.add(input)\n",
        "model.add(conv1)\n",
        "model.add(MaxPooling1D(2))\n",
        "model.add(LSTM(100))\n",
        "model.add(dense)\n",
        "model.compile(optimizer='adam', loss='CategoricalCrossentropy', metrics = 'accuracy')\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "SphxPhRlLrdI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab0d11ac-a504-42b9-9346-8a05b7de1db7"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_3 (Conv1D)           (None, 6958, 200)         800       \n",
            "                                                                 \n",
            " max_pooling1d_3 (MaxPooling  (None, 3479, 200)        0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " lstm_3 (LSTM)               (None, 100)               120400    \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 7)                 707       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 121,907\n",
            "Trainable params: 121,907\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(l, TabLabels2, test_size=0.1, random_state=42)\n",
        "model.fit(x=X_train, y=y_train, batch_size=20, epochs=5) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IUj4bwLeyXwK",
        "outputId": "5ca2baa7-9d8b-45dd-a9d8-7ee4d276bf48"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "15/15 [==============================] - 51s 138ms/step - loss: 1.8552 - accuracy: 0.2449\n",
            "Epoch 2/5\n",
            "15/15 [==============================] - 3s 186ms/step - loss: 1.8022 - accuracy: 0.2619\n",
            "Epoch 3/5\n",
            "15/15 [==============================] - 2s 156ms/step - loss: 1.8067 - accuracy: 0.2653\n",
            "Epoch 4/5\n",
            "15/15 [==============================] - 2s 136ms/step - loss: 1.8055 - accuracy: 0.2653\n",
            "Epoch 5/5\n",
            "15/15 [==============================] - 2s 137ms/step - loss: 1.8046 - accuracy: 0.2653\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff8705b5490>"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(x=X_test, y=y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gj0q6bsdyb7s",
        "outputId": "d0c7f760-33c7-4fa1-d05d-d1c304094e31"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:5 out of the last 789 calls to <function Model.make_test_function.<locals>.test_function at 0x7ff88b44c560> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "2/2 [==============================] - 1s 109ms/step - loss: 2.0572 - accuracy: 0.1515\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2.057241201400757, 0.1515151560306549]"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Bonus**\n",
        "The padding adds null values, in order to check whether we did a good strategy, use interpolation between landmarks of successive frames inorder to generate sequences with same number of frames, you can use linear or spline-based interpolation."
      ],
      "metadata": {
        "id": "zEwQ-qLZLx7C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Interpolation code here"
      ],
      "metadata": {
        "id": "VYYmsjKCMl87"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Perform the training and evaluate the performance of the models above after interpolation and compare the results comparing to padding."
      ],
      "metadata": {
        "id": "1Nb9NOqVMolM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CNN 1-D with interpolated data\n",
        "# your code here"
      ],
      "metadata": {
        "id": "7s9LYz96NC0X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CNN 2-D with interpolated data\n",
        "# your code here"
      ],
      "metadata": {
        "id": "Yh2HOYfANLjS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# RNN with interpolated data\n",
        "# your code here"
      ],
      "metadata": {
        "id": "7Y8Z9ZWJNNyw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LSTM with interpolated data\n",
        "# your code here"
      ],
      "metadata": {
        "id": "-TAEcUo5NQim"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CNN + LSTM with interpolated data\n",
        "# your code here"
      ],
      "metadata": {
        "id": "4W1H5eBKNT8i"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}